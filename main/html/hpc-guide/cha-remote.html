<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><title>SLE-HPC 15 SP6 | Administration Guide | Remote administration</title><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"/><link rel="schema.DCTERMS" href="http://purl.org/dc/terms/"/>
<meta name="title" content="Remote administration | SLE-HPC 15 SP6"/>
<meta name="description" content="High Performance Computing clusters usually consist of…"/>
<meta name="product-name" content="SUSE Linux Enterprise High Performance Computing"/>
<meta name="product-number" content="15 SP6"/>
<meta name="book-title" content="Administration Guide"/>
<meta name="chapter-title" content="Chapter 3. Remote administration"/>
<meta name="tracker-url" content="https://bugzilla.suse.com/enter_bug.cgi"/>
<meta name="tracker-type" content="bsc"/>
<meta name="tracker-bsc-assignee" content="tahlia.richardson@suse.com"/>
<meta name="tracker-bsc-component" content="Documentation"/>
<meta name="tracker-bsc-product" content="SUSE Linux Enterprise HPC 15 SP6"/>
<meta name="publisher" content="SUSE"/><meta property="og:title" content="Remote administration | SLE-HPC 15 SP6"/>
<meta property="og:description" content="High Performance Computing clusters usually consist of a small set of identical compute nodes. However, large clusters could…"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Remote administration | SLE-HPC 15 SP6"/>
<meta name="twitter:description" content="High Performance Computing clusters usually consist of a small set of identical compute nodes. However, large clusters could…"/>
<link rel="prev" href="installation.html" title="Chapter 2. Installation and upgrade"/><link rel="next" href="cha-nodes.html" title="Chapter 4. Hardware"/><script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/jquery-1.12.4.min.js" type="text/javascript"> </script><script src="static/js/script.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script><meta name="edit-url" content="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml"/></head><body class="draft wide offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Administration Guide</a><span> / </span><a class="crumb" href="cha-remote.html">Remote administration</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">Administration Guide</div><ol><li><a href="preface-administration.html" class=" "><span class="title-number"> </span><span class="title-name">Preface</span></a></li><li><a href="cha-introduction.html" class=" "><span class="title-number">1 </span><span class="title-name">Introduction</span></a></li><li><a href="installation.html" class=" "><span class="title-number">2 </span><span class="title-name">Installation and upgrade</span></a></li><li><a href="cha-remote.html" class=" you-are-here"><span class="title-number">3 </span><span class="title-name">Remote administration</span></a></li><li><a href="cha-nodes.html" class=" "><span class="title-number">4 </span><span class="title-name">Hardware</span></a></li><li><a href="cha-slurm.html" class=" "><span class="title-number">5 </span><span class="title-name">Slurm — utility for HPC workload management</span></a></li><li><a href="cha-monitoring.html" class=" "><span class="title-number">6 </span><span class="title-name">Monitoring and logging</span></a></li><li><a href="cha-compute.html" class=" "><span class="title-number">7 </span><span class="title-name">HPC user libraries</span></a></li><li><a href="cha-spack.html" class=" "><span class="title-number">8 </span><span class="title-name">Spack package management tool</span></a></li><li><a href="cha-dolly.html" class=" "><span class="title-number">9 </span><span class="title-name">Dolly clone tool</span></a></li><li><a href="apa.html" class=" "><span class="title-number">A </span><span class="title-name">GNU licenses</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section xml:lang="en" class="chapter" id="cha-remote" data-id-title="Remote administration"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname">SUSE Linux Enterprise High Performance Computing</span> <span class="productnumber">15 SP6</span></div><div><div class="title-container"><h1 class="title"><span class="title-number-name"><span class="title-number">3 </span><span class="title-name">Remote administration</span></span> <a title="Permalink" class="permalink" href="cha-remote.html#">#</a></h1><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div></div><div><div class="abstract"><p>
    High Performance Computing clusters usually consist of a small set of identical compute
    nodes. However, large clusters could consist of thousands of machines.
    This chapter describes tools to help manage the compute nodes in a cluster.
   </p></div></div></div></div><section class="sect1" id="sec-remote-genders" data-id-title="Genders — static cluster configuration database"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">3.1 </span><span class="title-name">Genders — static cluster configuration database</span></span> <a title="Permalink" class="permalink" href="cha-remote.html#sec-remote-genders">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   <span class="emphasis"><em>Genders</em></span> is a static cluster configuration database used
   for configuration management. It allows grouping and addressing sets of
   nodes by attributes, and is used by a variety of tools. The Genders
   database is a text file that is usually replicated on each node in a
   cluster.
  </p><p>
   Perl, Python, Lua, C, and C++ bindings are supplied with Genders. Each
   package provides <code class="command">man</code> pages or other documentation which
   describes the APIs.
  </p><section class="sect2" id="sec-genders-db" data-id-title="Genders database format"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">3.1.1 </span><span class="title-name">Genders database format</span></span> <a title="Permalink" class="permalink" href="cha-remote.html#sec-genders-db">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   The Genders database in SUSE Linux Enterprise High Performance Computing is a plain-text file called
   <code class="filename">/etc/genders</code>. It contains a list of node names with
   their attributes. Each line of the database can have one of the following
   formats.
  </p><div class="verbatim-wrap"><pre class="screen">nodename                attr[=value],attr[=value],...
nodename1,nodename2,... attr[=value],attr[=value],...
nodenames[A-B]          attr[=value],attr[=value],...</pre></div><p>
   Node names are listed without their domain, and are followed by any number of
   spaces or tabs, then the comma-separated list of attributes. Every
   attribute can optionally have a value. The substitution string
   <code class="literal">%n</code> can be used in an attribute value to represent the node
   name. Node names can be listed on multiple lines, so a node's attributes can
   be specified on multiple lines. However, no single node can have duplicate
   attributes.
  </p><p>
   The attribute list must not contain spaces, and there is no provision for
   continuation lines.  Commas and equals characters (<code class="literal">=</code>) are
   special, and cannot appear in attribute names or values. Comments are
   prefixed with the hash character (<code class="literal">#</code>) and can appear
   anywhere in the file.
  </p><p>
   Ranges for node names can be specified in the form
   <code class="literal">prefix[a-c,n-p,...]</code> as an alternative to explicit lists
   of node names. For example, <code class="literal">node[01-03,06]</code> would specify
   <code class="literal">node01</code>, <code class="literal">node02</code>, <code class="literal">node03</code>,
   and <code class="literal">node06</code>.
  </p></section><section class="sect2" id="sec-nodeattr" data-id-title="Nodeattr usage"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">3.1.2 </span><span class="title-name">Nodeattr usage</span></span> <a title="Permalink" class="permalink" href="cha-remote.html#sec-nodeattr">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    The command line utility <code class="command">nodeattr</code> can be used to query data
    in the genders file. When the genders file is replicated on all nodes, a query
    can be done without network access. The genders file can be called as follows:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>nodeattr [-q | -n | -s] [-r] attr[=val]</pre></div><p>
   <code class="literal">-q</code> is the default option and prints a list of nodes
   with <code class="literal">attr[=val]</code>.
  </p><p>
   The <code class="literal">-c</code> or <code class="literal">-s</code> options give a
   comma-separated or space-separated list of nodes with
   <code class="literal">attr[=val]</code>.
  </p><p>
   If none of the formatting options are specified, <code class="command">nodeattr</code>
   returns a zero value if the local node has the specified attribute, and
   non-zero otherwise. The <code class="literal">-v</code> option causes any value
   associated with the attribute to go to <code class="literal">stdout</code>. If a node
   name is specified before the attribute, the specified node is queried instead
   of the local node.
  </p><p>
    To print all attributes for a particular node, run the following command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>nodeattr -l [node]</pre></div><p>
   If no node parameter is given, all attributes of the local node are printed.
  </p><p>
   To perform a syntax check of the genders database, run the following command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>nodeattr [-f genders] -k</pre></div><p>
   To specify an alternative database location, use the option
   <code class="literal">-f</code>.
  </p></section></section><section class="sect1" id="sec-remote-pdsh" data-id-title="pdsh — parallel remote shell program"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">3.2 </span><span class="title-name">pdsh — parallel remote shell program</span></span> <a title="Permalink" class="permalink" href="cha-remote.html#sec-remote-pdsh">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   <code class="command">pdsh</code> is a parallel remote shell that can be used
   with multiple back-ends for remote connections. It can run a command on
   multiple machines in parallel.
  </p><p>
   To install <span class="package">pdsh</span>, run the command
   <code class="command">zypper in pdsh</code>.
  </p><p>
   In SUSE Linux Enterprise High Performance Computing, the back-ends <code class="literal">ssh</code>,
   <code class="literal">mrsh</code>, and <code class="literal">exec</code> are supported. The
   <code class="literal">ssh</code> back-end is the default. Non-default login methods
   can be used by setting the <code class="literal">PDSH_RCMD_TYPE</code>
   environment variable, or by using the <code class="literal">-R</code> command
   argument.
  </p><p>
   When using the <code class="literal">ssh</code> back-end, you must use a
   non-interactive (passwordless) login method.
  </p><p>
   The <code class="literal">mrsh</code> back-end requires the
   <code class="literal">mrshd</code> daemon to be running on the client. The
   <code class="literal">mrsh</code> back-end does not require the use of reserved
   sockets, so it does not suffer from port exhaustion when running commands
   on many machines in parallel. For information about setting up the system to
   use this back-end, see <a class="xref" href="cha-remote.html#sec-remote-mrsh" title="3.5. mrsh/mrlogin — remote login using MUNGE authentication">Section 3.5, “mrsh/mrlogin — remote login using MUNGE authentication”</a>.
  </p><p>
   Remote machines can be specified on the command line, or
   <code class="command">pdsh</code> can use a <code class="filename">machines</code> file
   (<code class="filename">/etc/pdsh/machines</code>), <code class="command">dsh</code> (Dancer's
   shell)-style groups or netgroups. It can also target nodes based on the
   currently running Slurm jobs.
  </p><p>
   The different ways to select target hosts are realized by modules. Some
   of these modules provide identical options to <code class="command">pdsh</code>.
   The module loaded first will win and handle the option. Therefore, we
   recommended using a single method and specifying this with
   the <code class="literal">-M</code> option.
  </p><p>
   The <code class="filename">machines</code> file lists all target hosts, one per
   line. The appropriate netgroup can be selected with the
   <code class="literal">-g</code> command line option.
  </p><p>
   The following host-list plugins for <code class="command">pdsh</code> are supported:
   <code class="literal">machines</code>, <code class="literal">slurm</code>,
   <code class="literal">netgroup</code> and <code class="literal">dshgroup</code>.
   Each host-list plugin is provided in a separate package. This avoids
   conflicts between command line options for different plugins which
   happen to be identical, and helps to keep installations small and free
   of unneeded dependencies. Package dependencies have been set to prevent
   the installation of plugins with conflicting command options. To install one
   of the plugins, run:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>sudo zypper in pdsh-<em class="replaceable">PLUGIN_NAME</em></pre></div><p>
   For more information, see the <code class="command">man</code> page <code class="command">pdsh</code>.
  </p></section><section class="sect1" id="sec-remote-powerman" data-id-title="PowerMan — centralized power control for clusters"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">3.3 </span><span class="title-name">PowerMan — centralized power control for clusters</span></span> <a title="Permalink" class="permalink" href="cha-remote.html#sec-remote-powerman">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   PowerMan can control the following remote power control devices (RPC) from a
   central location:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     local devices connected to a serial port
    </p></li><li class="listitem"><p>
     RPCs listening on a TCP socket
    </p></li><li class="listitem"><p>
     RPCs that are accessed through an external program
    </p></li></ul></div><p>
   The communication to RPCs is controlled by <span class="quote">“<span class="quote">expect</span>”</span>-like
   scripts. For a
   list of currently supported devices, see the configuration file
   <code class="filename">/etc/powerman/powerman.conf</code>.
  </p><p>
   To install PowerMan, run <code class="command">zypper in powerman</code>.
  </p><p>
   To configure PowerMan, include the appropriate device file for your RPC
   (<code class="filename">/etc/powerman/*.dev</code>) in
   <code class="filename">/etc/powerman/powerman.conf</code> and add devices and
   nodes. The device <span class="quote">“<span class="quote">type</span>”</span> needs to match the
   <span class="quote">“<span class="quote">specification</span>”</span> name in one
   of the included device files. The list of <span class="quote">“<span class="quote">plugs</span>”</span> used for
   nodes needs to
   match an entry in the <span class="quote">“<span class="quote">plug name</span>”</span> list.
  </p><p>
   After configuring PowerMan, start its service:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>sudo systemctl start powerman.service</pre></div><p>
   To start PowerMan automatically after every boot, run the following command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>sudo systemctl enable powerman.service</pre></div><p>
   Optionally, PowerMan can connect to a remote PowerMan instance. To
   enable this, add the option <code class="literal">listen</code> to
   <code class="filename">/etc/powerman/powerman.conf</code>.
  </p><div id="id-1.5.5.12" data-id-title="Unencrypted transfer" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg"/><div class="admon-title">Important: Unencrypted transfer</div><p>
    When connecting to a remote PowerMan instance, data is transferred
    unencrypted. Therefore, use this feature only if the network is
    appropriately secured.
   </p></div></section><section class="sect1" id="sec-remote-munge" data-id-title="MUNGE authentication"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">3.4 </span><span class="title-name">MUNGE authentication</span></span> <a title="Permalink" class="permalink" href="cha-remote.html#sec-remote-munge">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   MUNGE allows for secure communications between different machines that
   share the same secret key. The most common use case is the Slurm workload
   manager, which uses MUNGE for the encryption of its messages. Another use
   case is authentication for the parallel shell mrsh.
  </p><section class="sect2" id="sec-setting-up-munge" data-id-title="Setting up MUNGE authentication"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">3.4.1 </span><span class="title-name">Setting up MUNGE authentication</span></span> <a title="Permalink" class="permalink" href="cha-remote.html#sec-setting-up-munge">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    MUNGE uses UID/GID values to uniquely identify and authenticate users,
    so you must ensure that users who will authenticate across a network
    have matching UIDs and GIDs across all nodes.
   </p><p>
    MUNGE credentials have a limited time-to-live, so you must ensure that the
    time is synchronized across the entire cluster.
   </p><p>
    MUNGE is installed with the command <code class="command">zypper in munge</code>.
    This also installs further required packages. A separate
    <span class="package">munge-devel</span> package is available to build applications
    that require MUNGE authentication.
   </p><p>
    When installing the <span class="package">munge</span> package, a new key is generated
    on every system. However, the entire cluster needs to use the same MUNGE
    key. Therefore, you must securely copy the MUNGE key from one system to
    all the other nodes in the cluster. You can accomplish this by using
    <code class="command">pdsh</code> with SSH. Ensure that the key is only readable
    by the <code class="literal">munge</code> user (permissions mask
    <code class="literal">0400</code>).
   </p><div class="procedure" id="pro-remote-munge" data-id-title="Setting up MUNGE authentication"><div class="title-container"><div class="procedure-title-wrap"><div class="procedure-title"><span class="title-number-name"><span class="title-number">Procedure 3.1: </span><span class="title-name">Setting up MUNGE authentication </span></span><a title="Permalink" class="permalink" href="cha-remote.html#pro-remote-munge">#</a></div></div><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div><div class="procedure-contents"><ol class="procedure" type="1"><li class="step"><p>
      On the server where MUNGE is installed, check the permissions, owner,
      and file type of the key file <code class="filename">/etc/munge/munge.key</code>:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>sudo stat --format "%F %a %G %U %n" /etc/munge/munge.key</pre></div><p>
      The settings should be as follows:
     </p><div class="verbatim-wrap"><pre class="screen">400 regular file munge munge /etc/munge/munge.key</pre></div></li><li class="step"><p>
      Calculate the MD5 sum of <code class="filename">munge.key</code>:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>sudo md5sum /etc/munge/munge.key</pre></div></li><li class="step"><p>
      Copy the key to the listed nodes using <code class="command">pdcp</code>:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>pdcp -R ssh -w <em class="replaceable">NODELIST</em> /etc/munge/munge.key /etc/munge/munge.key</pre></div></li><li class="step"><p>
      Check the key settings on the remote nodes:
     </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>pdsh -R ssh -w <em class="replaceable">HOSTLIST</em> stat --format \"%F %a %G %U %n\" /etc/munge/munge.key
<code class="prompt user">&gt; </code>pdsh -R ssh -w <em class="replaceable">HOSTLIST</em> md5sum /etc/munge/munge.key</pre></div><p>
      Ensure that they match the settings on the MUNGE server.
     </p></li></ol></div></div></section><section class="sect2" id="sec-enabling-and-starting-munge" data-id-title="Enabling and starting MUNGE"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">3.4.2 </span><span class="title-name">Enabling and starting MUNGE</span></span> <a title="Permalink" class="permalink" href="cha-remote.html#sec-enabling-and-starting-munge">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div></div></div></div><p>
    <code class="systemitem">munged</code> must be running on all nodes
    that use MUNGE authentication. If MUNGE is used for
    authentication across the network, it needs to run on each side of the
    communications link.
   </p><p>
    To start the service and ensure it is started after every reboot, run
    the following command on each node:
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>sudo systemctl enable --now munge.service</pre></div><p>
     You can also use <code class="command">pdsh</code> to run this command on multiple
     nodes at once.
   </p></section></section><section class="sect1" id="sec-remote-mrsh" data-id-title="mrsh/mrlogin — remote login using MUNGE authentication"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">3.5 </span><span class="title-name">mrsh/mrlogin — remote login using MUNGE authentication</span></span> <a title="Permalink" class="permalink" href="cha-remote.html#sec-remote-mrsh">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a><a target="_blank" class="icon-editsource" href="https://github.com/SUSE/doc-hpc/edit/main/xml/remote_administration.xml" title="Edit source document"> </a></div></div></div></div></div><p>
   <span class="emphasis"><em>mrsh</em></span> is a set of remote shell programs using the
   <span class="emphasis"><em>MUNGE</em></span> authentication system instead of reserved ports
   for security.
  </p><p>
   It can be used as a drop-in replacement for <code class="literal">rsh</code> and
   <code class="literal">rlogin</code>.
  </p><p>
   To install mrsh, do the following:
  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
     If only the mrsh client is required (without
     allowing remote login to this machine), use:
     <code class="command">zypper in mrsh</code>.
    </p></li><li class="listitem"><p>
     To allow logging in to a machine, the server must be installed:
     <code class="command">zypper in mrsh-server</code>.
    </p></li><li class="listitem"><p>
     To get a drop-in replacement for <code class="command">rsh</code> and
     <code class="command">rlogin</code>, run: <code class="command">zypper in
     mrsh-rsh-server-compat</code> or <code class="command">zypper in
     mrsh-rsh-compat</code>.
    </p></li></ul></div><p>
   To set up a cluster of machines allowing remote login from each other,
   first follow the instructions for setting up and starting MUNGE
   authentication in <a class="xref" href="cha-remote.html#sec-remote-munge" title="3.4. MUNGE authentication">Section 3.4, “MUNGE authentication”</a>. After the MUNGE service
   successfully starts, enable and start <code class="command">mrlogin</code>
   on each machine on which the user will log in:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>sudo systemctl enable mrlogind.socket mrshd.socket
<code class="prompt user">&gt; </code>sudo systemctl start mrlogind.socket mrshd.socket</pre></div><p>
   To start mrsh support at boot, run the following command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>sudo systemctl enable munge.service
<code class="prompt user">&gt; </code>sudo systemctl enable mrlogin.service</pre></div><p>
   We do not recommend using mrsh when logged in as the
   user <code class="systemitem">root</code>. This is disabled by
   default. To enable it anyway, run the following command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code>sudo echo "mrsh" &gt;&gt; /etc/securetty
<code class="prompt user">&gt; </code>sudo echo "mrlogin" &gt;&gt; /etc/securetty</pre></div></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="installation.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 2 </span>Installation and upgrade</span></a> </div><div><a class="pagination-link next" href="cha-nodes.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 4 </span>Hardware</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="sect1"><a href="cha-remote.html#sec-remote-genders"><span class="title-number">3.1 </span><span class="title-name">Genders — static cluster configuration database</span></a></span></li><li><span class="sect1"><a href="cha-remote.html#sec-remote-pdsh"><span class="title-number">3.2 </span><span class="title-name">pdsh — parallel remote shell program</span></a></span></li><li><span class="sect1"><a href="cha-remote.html#sec-remote-powerman"><span class="title-number">3.3 </span><span class="title-name">PowerMan — centralized power control for clusters</span></a></span></li><li><span class="sect1"><a href="cha-remote.html#sec-remote-munge"><span class="title-number">3.4 </span><span class="title-name">MUNGE authentication</span></a></span></li><li><span class="sect1"><a href="cha-remote.html#sec-remote-mrsh"><span class="title-number">3.5 </span><span class="title-name">mrsh/mrlogin — remote login using MUNGE authentication</span></a></span></li></ul></div><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter/X"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2024</span></div></div></footer></body></html>